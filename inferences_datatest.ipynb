{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMT_KnOzS_t2","outputId":"6768addb-6116-4a02-ece2-62da2b6f2e90","executionInfo":{"status":"ok","timestamp":1718543923874,"user_tz":-420,"elapsed":3090,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["!pip install ultralytics unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7VVuU5gFqpZ","executionInfo":{"status":"ok","timestamp":1718542138644,"user_tz":-420,"elapsed":872,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}},"outputId":"8618ee35-2c41-48fe-a942-043788144211"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.32 ultralytics-thop-0.2.8 unidecode-1.3.8\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","# Đường dẫn đến thư mục data_test\n","data_dir = '/content/drive/MyDrive/object_detection/data_test'\n","\n","datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Tạo generator cho dữ liệu kiểm tra\n","test_generator = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=(224, 224),  # Kích thước của ảnh đầu vào (thay đổi nếu cần thiết)\n","    batch_size=32,\n","    class_mode='categorical',\n","    shuffle=False  # Không xáo trộn để đảm bảo thứ tự của nhãn\n",")\n","\n","# Danh sách nhãn của mô hình CNN\n","# ['banh-hoi-heo-quay', 'bun-bo-hue', 'bun-ca', 'bun-dau-mam-tom', 'bun-hai-san-be-be', 'bun-moc', 'bun-muc',\n","# 'bun-nuoc-leo', 'cao-lau', 'com-ga', 'com-tam-long-xuyen', 'hu-tieu-my-tho', 'mi-quang', 'pho-ha-noi']\n","labels_cnn = list(test_generator.class_indices.keys())\n","class_names = list(test_generator.class_indices.keys())\n","print(labels_cnn)\n","\n","labels_d2d = ['bun-ca', 'hu-tieu-my-tho', 'bun-nuoc-leo', 'com-tam-long-xuyen', 'bun-hai-san-be-be', 'banh-hoi-heo-quay',\n","              'com-ga', 'cao-lau', 'mi-quang', 'bun-bo-hue', 'pho-ha-noi', 'bun-muc', 'bun-moc', 'bun-dau-mam-tom']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDaD9DJ7TNVB","outputId":"35ae3d8f-d7c7-4609-f7d4-8e34b8c81f05","executionInfo":{"status":"ok","timestamp":1718542264861,"user_tz":-420,"elapsed":361,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 380 images belonging to 14 classes.\n","['banh-hoi-heo-quay', 'bun-bo-hue', 'bun-ca', 'bun-dau-mam-tom', 'bun-hai-san-be-be', 'bun-moc', 'bun-muc', 'bun-nuoc-leo', 'cao-lau', 'com-ga', 'com-tam-long-xuyen', 'hu-tieu-my-tho', 'mi-quang', 'pho-ha-noi']\n"]}]},{"cell_type":"code","source":["class_indices = test_generator.class_indices\n","\n","# Tạo dictionary để ánh xạ từ tên nhãn sang số\n","label_to_index = {name: index for index, name in class_indices.items()}\n","\n","print(label_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AO79PoMvtH4x","outputId":"95f86b56-7b83-49d2-bdda-680eb345feb2","executionInfo":{"status":"ok","timestamp":1718542278991,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 'banh-hoi-heo-quay', 1: 'bun-bo-hue', 2: 'bun-ca', 3: 'bun-dau-mam-tom', 4: 'bun-hai-san-be-be', 5: 'bun-moc', 6: 'bun-muc', 7: 'bun-nuoc-leo', 8: 'cao-lau', 9: 'com-ga', 10: 'com-tam-long-xuyen', 11: 'hu-tieu-my-tho', 12: 'mi-quang', 13: 'pho-ha-noi'}\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from ultralytics import YOLO, RTDETR\n","\n","excel_file_path = '/content/drive/MyDrive/object_detection/rules.xlsx'\n","classes_path = '/content/drive/MyDrive/object_detection/classes.txt'\n","\n","df = pd.read_excel(excel_file_path)\n","classes_ingre = []\n","\n","with open(classes_path, 'r', encoding='utf-8') as file:\n","    lines = [line.strip() for line in file]\n","    classes_ingre = lines\n","\n","model_yolov8 = YOLO('/content/drive/MyDrive/object_detection/models/yolov8_best_862.pt')\n","model_yolov9 = YOLO('/content/drive/MyDrive/object_detection/models/yolov9_best_85.pt')\n","model_rtdetr = RTDETR('/content/drive/MyDrive/object_detection/models/rt-detr_best_865.pt')"],"metadata":{"id":"lZ7TzKVhh8EU","executionInfo":{"status":"ok","timestamp":1718542168915,"user_tz":-420,"elapsed":25458,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from unidecode import unidecode\n","\n","def preprocess_dataframe():\n","    global df\n","    normalized_df = df.drop(df.columns[[0, -1]], axis=1)\n","\n","    for index, row in normalized_df.iterrows():\n","        for col in normalized_df.columns:\n","            value = row[col]\n","            if pd.notna(value):\n","                name_without_accents = unidecode(value)\n","                values = name_without_accents.split(', ')\n","                for i in range(len(values)):\n","                    values[i] = values[i].replace(' ', '-')\n","                row[col] = ', '.join(values)\n","\n","    return normalized_df\n","\n","normalized_df = preprocess_dataframe()"],"metadata":{"id":"JEZA-t0RjHez","executionInfo":{"status":"ok","timestamp":1718542172801,"user_tz":-420,"elapsed":366,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def detect_ingredients(model, img):\n","    results = model(img, conf=0.3, save=False)\n","    names = results[0].names\n","    detected_cls = results[0].boxes.cls.tolist()\n","    boxes = results[0].boxes.xyxy.tolist()\n","    return names, detected_cls, boxes"],"metadata":{"id":"DKM9ZjxTj7KI","executionInfo":{"status":"ok","timestamp":1718542175719,"user_tz":-420,"elapsed":2,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def find_foodname_ver_narrow(set_detected_ingre):\n","    global normalized_df\n","    global df\n","    global food_names\n","    distances = []\n","\n","    for index, row in normalized_df.iterrows():\n","        values = {}\n","        values[\"prior\"] = set(row[\"Priorities\"].split(', '))\n","        values[\"main\"] = set(row[\"Ingredients\"].split(', '))\n","        values[\"extra\"] = set(row[\"Secondary Ingredients\"].split(', ')) if pd.notna(row[\"Secondary Ingredients\"]) else set()\n","\n","        # Không khớp với ƯU TIÊN\n","        no_match_prior = values[\"prior\"].difference(set_detected_ingre)\n","\n","        # Không khớp với CHÍNH\n","        no_match_main = values[\"main\"].difference(set_detected_ingre)\n","\n","        # Khớp với PHỤ\n","        match_extra = values[\"extra\"].intersection(set_detected_ingre)\n","\n","        # Phần tử thuộc detect nhưng không thuộc bộ luật CHÍNH & PHỤ\n","        combine = values[\"prior\"].union(values[\"main\"])\n","        combine = combine.union(values[\"extra\"])\n","        redundancy = set_detected_ingre.difference(combine)\n","\n","        shortage_score = (len(no_match_prior) * 10) + len(no_match_main) - (len(match_extra)*0.5)\n","        redundancy_score = len(redundancy)\n","        score = shortage_score + redundancy_score\n","\n","        # print(index, score)\n","        distances.append(score)\n","\n","    min_value = min(distances)\n","    min_indices = [i for i, value in enumerate(distances) if value == min_value]\n","\n","    predicted_food = []\n","    for min_index in min_indices:\n","        predicted_food.append(labels_d2d[min_index])\n","\n","    return distances, predicted_food[0]"],"metadata":{"id":"-x-VGK4hjKqj","executionInfo":{"status":"ok","timestamp":1718542178403,"user_tz":-420,"elapsed":2,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def convertIdx2Class(set_index, classes):\n","    result_set = {classes[item] for item in set_index}\n","    return result_set"],"metadata":{"id":"euR8p_IolRlC","executionInfo":{"status":"ok","timestamp":1718542182521,"user_tz":-420,"elapsed":362,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["import cv2\n","\n","def recognize_food(detector, file_predict):\n","    global classes_ingre\n","\n","    img = cv2.imread(file_predict)\n","    detector_names, detector_detected_cls, detector_boxes = detect_ingredients(detector, img)\n","\n","    detector_rm_duplicates = set(detector_detected_cls)\n","    detector_rm_duplicates = [int(number) for number in detector_rm_duplicates]\n","    detector_detected_cls = list(detector_rm_duplicates)\n","    detector_rm_duplicates = convertIdx2Class(detector_rm_duplicates, classes_ingre)\n","\n","    detector_distances, detector_predicted_food = find_foodname_ver_narrow(detector_rm_duplicates)\n","\n","    return detector_predicted_food"],"metadata":{"id":"gRlkw_l1kBNB","executionInfo":{"status":"ok","timestamp":1718542184623,"user_tz":-420,"elapsed":356,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Kết quả Yolov8 + D2D"],"metadata":{"id":"CQQ8ObydlzkH"}},{"cell_type":"code","source":["file_paths = test_generator.filepaths\n","\n","predY = []\n","\n","for index, img_predict in enumerate(file_paths):\n","    print(index)\n","    food = recognize_food(model_yolov8, img_predict)\n","    # Chuyển đổi từ tên nhãn sang số tương ứng\n","    predicted_index = next((index for index, label in label_to_index.items() if label == food), None)\n","    predY.append(predicted_index)\n","    print(\"------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8_QDe8vflzFS","outputId":"16f96446-6f1b-40aa-aed1-1a32983c6e4e","executionInfo":{"status":"ok","timestamp":1718542460233,"user_tz":-420,"elapsed":164337,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","\n","0: 544x640 8 thit-heo-quays, 8 banh-hois, 1 dua-chua, 88.9ms\n","Speed: 5.2ms preprocess, 88.9ms inference, 2.2ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","1\n","\n","0: 640x576 3 thit-heo-quays, 6 banh-hois, 1 dua-chua, 152.6ms\n","Speed: 3.0ms preprocess, 152.6ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","2\n","\n","0: 608x640 6 thit-heo-quays, 3 banh-hois, 1 dua-chua, 171.0ms\n","Speed: 4.8ms preprocess, 171.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","3\n","\n","0: 384x640 7 thit-heo-quays, 1 banh-hoi, 77.5ms\n","Speed: 4.4ms preprocess, 77.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","4\n","\n","0: 512x640 5 thit-heo-quays, 8 banh-hois, 78.9ms\n","Speed: 4.3ms preprocess, 78.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","5\n","\n","0: 512x640 16 thit-heo-quays, 19 banh-hois, 74.0ms\n","Speed: 4.8ms preprocess, 74.0ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","6\n","\n","0: 640x480 5 thit-heo-quays, 6 banh-hois, 1 dua-chua, 96.3ms\n","Speed: 2.9ms preprocess, 96.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n","------\n","7\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n"]},{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 4 thit-heo-quays, 5 banh-hois, 62.7ms\n","Speed: 3.0ms preprocess, 62.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","8\n","\n","0: 544x640 10 thit-heo-quays, 4 banh-hois, 89.5ms\n","Speed: 3.7ms preprocess, 89.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","9\n","\n","0: 480x640 3 thit-heo-quays, 2 banh-hois, 74.9ms\n","Speed: 3.1ms preprocess, 74.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","10\n","\n","0: 640x640 10 thit-heo-quays, 7 banh-hois, 88.0ms\n","Speed: 5.5ms preprocess, 88.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","11\n","\n","0: 640x640 10 thit-heo-quays, 7 banh-hois, 87.5ms\n","Speed: 6.4ms preprocess, 87.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","12\n","\n","0: 640x480 4 thit-heo-quays, 3 banh-hois, 62.6ms\n","Speed: 4.6ms preprocess, 62.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","------\n","13\n","\n","0: 544x640 6 banh-hois, 1 dua-chua, 3 cha-gios, 74.9ms\n","Speed: 3.2ms preprocess, 74.9ms inference, 2.5ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","14\n","\n","0: 544x640 7 thit-heo-quays, 15 banh-hois, 9 dau-hus, 74.1ms\n","Speed: 3.9ms preprocess, 74.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","15\n","\n","0: 576x640 5 buns, 2 thit-bos, 79.0ms\n","Speed: 4.6ms preprocess, 79.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","16\n","\n","0: 512x640 3 buns, 7 thit-bos, 75.1ms\n","Speed: 3.2ms preprocess, 75.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","17\n","\n","0: 608x640 4 buns, 5 thit-bos, 94.4ms\n","Speed: 4.2ms preprocess, 94.4ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","18\n","\n","0: 512x640 1 bun, 7 thit-bos, 77.6ms\n","Speed: 4.1ms preprocess, 77.6ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","19\n","\n","0: 544x640 1 bun, 3 thit-bos, 90.4ms\n","Speed: 3.8ms preprocess, 90.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","20\n","\n","0: 640x608 1 bun, 1 thit-heo, 2 thit-bos, 109.8ms\n","Speed: 3.7ms preprocess, 109.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","21\n","\n","0: 640x640 1 bun, 2 thit-bos, 87.5ms\n","Speed: 6.0ms preprocess, 87.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","22\n","\n","0: 448x640 3 buns, 8 thit-bos, 120.0ms\n","Speed: 2.5ms preprocess, 120.0ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","23\n","\n","0: 608x640 1 bun, 2 thit-bos, 79.4ms\n","Speed: 7.0ms preprocess, 79.4ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","24\n","\n","0: 640x640 1 bun, 2 thit-bos, 1 dau-hu, 82.2ms\n","Speed: 4.9ms preprocess, 82.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","25\n","\n","0: 608x640 2 buns, 4 thit-bos, 78.0ms\n","Speed: 4.6ms preprocess, 78.0ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","26\n","\n","0: 640x448 2 buns, 3 thit-bos, 72.0ms\n","Speed: 3.4ms preprocess, 72.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n","------\n","27\n","\n","0: 576x640 1 bun, 3 thit-bos, 74.6ms\n","Speed: 4.1ms preprocess, 74.6ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","28\n","\n","0: 640x576 2 buns, 3 thit-bos, 93.2ms\n","Speed: 5.1ms preprocess, 93.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","29\n","\n","0: 640x640 3 buns, 6 thit-bos, 86.4ms\n","Speed: 4.6ms preprocess, 86.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","30\n","\n","0: 640x608 1 bun, 3 thit-bos, 77.7ms\n","Speed: 4.7ms preprocess, 77.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","31\n","\n","0: 544x640 3 buns, 5 thit-bos, 74.2ms\n","Speed: 3.8ms preprocess, 74.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","32\n","\n","0: 512x640 2 buns, 3 thit-heos, 1 thit-bo, 64.0ms\n","Speed: 3.8ms preprocess, 64.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","33\n","\n","0: 480x640 2 buns, 4 thit-bos, 61.3ms\n","Speed: 6.0ms preprocess, 61.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","34\n","\n","0: 608x640 1 bun, 1 thit-heo, 5 thit-bos, 95.5ms\n","Speed: 3.6ms preprocess, 95.5ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","35\n","\n","0: 576x640 5 buns, 3 thit-bos, 79.5ms\n","Speed: 3.4ms preprocess, 79.5ms inference, 2.1ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","36\n","\n","0: 384x640 2 buns, 3 thit-bos, 55.1ms\n","Speed: 2.8ms preprocess, 55.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","37\n","\n","0: 544x640 3 buns, 7 thit-bos, 78.4ms\n","Speed: 4.5ms preprocess, 78.4ms inference, 1.7ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","38\n","\n","0: 480x640 5 buns, 7 thit-bos, 1 rau-ram, 65.0ms\n","Speed: 3.1ms preprocess, 65.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","39\n","\n","0: 608x640 2 buns, 1 thit-bo, 94.4ms\n","Speed: 5.6ms preprocess, 94.4ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","40\n","\n","0: 640x608 1 bun, 4 thit-bos, 82.2ms\n","Speed: 4.9ms preprocess, 82.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","41\n","\n","0: 608x640 4 buns, 6 thit-bos, 82.0ms\n","Speed: 6.0ms preprocess, 82.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","42\n","\n","0: 608x640 4 buns, 3 thit-bos, 81.1ms\n","Speed: 6.1ms preprocess, 81.1ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","43\n","\n","0: 640x640 2 buns, 2 thit-bos, 83.4ms\n","Speed: 5.4ms preprocess, 83.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","44\n","\n","0: 640x608 2 buns, 1 thit-bo, 78.0ms\n","Speed: 5.2ms preprocess, 78.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","45\n","\n","0: 608x640 1 bun, 4 thit-bos, 77.8ms\n","Speed: 5.9ms preprocess, 77.8ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","46\n","\n","0: 640x640 2 buns, 6 thit-bos, 80.7ms\n","Speed: 4.7ms preprocess, 80.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","47\n","\n","0: 480x640 3 buns, 2 thit-bos, 63.5ms\n","Speed: 6.0ms preprocess, 63.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","48\n","\n","0: 384x640 1 thit-heo, 1 thit-bo, 1 pho, 63.2ms\n","Speed: 2.3ms preprocess, 63.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","49\n","\n","0: 512x640 2 buns, 10 thit-bos, 77.4ms\n","Speed: 2.7ms preprocess, 77.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","50\n","\n","0: 544x640 1 bun, 1 thit-heo, 4 thit-bos, 89.9ms\n","Speed: 5.8ms preprocess, 89.9ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","51\n","\n","0: 480x640 4 cas, 4 buns, 2 toms, 67.4ms\n","Speed: 5.8ms preprocess, 67.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","52\n","\n","0: 480x640 3 cas, 1 bun, 2 toms, 1 rau-ram, 65.9ms\n","Speed: 3.9ms preprocess, 65.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","53\n","\n","0: 640x448 4 cas, 1 bun, 65.4ms\n","Speed: 1.6ms preprocess, 65.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 448)\n","------\n","54\n","\n","0: 544x640 2 cas, 2 buns, 3 toms, 81.1ms\n","Speed: 2.9ms preprocess, 81.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","55\n","\n","0: 384x640 3 cas, 3 buns, 3 toms, 60.8ms\n","Speed: 2.3ms preprocess, 60.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","56\n","\n","0: 512x640 3 cas, 4 buns, 3 toms, 74.9ms\n","Speed: 2.4ms preprocess, 74.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","57\n","\n","0: 640x480 2 cas, 2 buns, 74.4ms\n","Speed: 3.0ms preprocess, 74.4ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n","------\n","58\n","\n","0: 640x640 3 cas, 4 buns, 6 toms, 98.0ms\n","Speed: 5.2ms preprocess, 98.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","59\n","\n","0: 448x640 2 cas, 1 bun, 1 rau-ram, 60.1ms\n","Speed: 5.9ms preprocess, 60.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","60\n","\n","0: 512x640 3 cas, 1 bun, 1 rau-ram, 63.3ms\n","Speed: 3.5ms preprocess, 63.3ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","61\n","\n","0: 512x640 2 cas, 2 buns, 62.1ms\n","Speed: 3.3ms preprocess, 62.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","62\n","\n","0: 608x640 3 cas, 3 buns, 1 thit-heo-quay, 79.4ms\n","Speed: 3.3ms preprocess, 79.4ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","63\n","\n","0: 640x640 2 cas, 2 buns, 1 rau-ram, 90.0ms\n","Speed: 3.2ms preprocess, 90.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","64\n","\n","0: 448x640 7 cas, 2 buns, 60.9ms\n","Speed: 3.5ms preprocess, 60.9ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","65\n","\n","0: 512x640 2 buns, 63.1ms\n","Speed: 2.7ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","66\n","\n","0: 448x640 4 cas, 1 bun, 3 rau-rams, 62.7ms\n","Speed: 5.5ms preprocess, 62.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","67\n","\n","0: 608x640 2 cas, 1 bun, 79.2ms\n","Speed: 3.6ms preprocess, 79.2ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","68\n","\n","0: 544x640 2 cas, 1 bun, 5 rau-rams, 87.6ms\n","Speed: 3.4ms preprocess, 87.6ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","69\n","\n","0: 640x640 1 ca, 1 bun, 97.5ms\n","Speed: 4.9ms preprocess, 97.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","70\n","\n","0: 640x640 3 cas, 2 buns, 4 toms, 1 rau-ram, 96.9ms\n","Speed: 3.5ms preprocess, 96.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","71\n","\n","0: 608x640 2 buns, 4 thit-heos, 2 cha-coms, 1 dau-hu, 1 cha-gio, 79.5ms\n","Speed: 3.9ms preprocess, 79.5ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","72\n","\n","0: 608x640 3 buns, 12 thit-heos, 1 dau-hu, 78.1ms\n","Speed: 3.5ms preprocess, 78.1ms inference, 1.5ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","73\n","\n","0: 608x640 1 bun, 1 thit-heo, 2 cha-coms, 3 doi-suns, 13 dau-hus, 1 cha-gio, 78.2ms\n","Speed: 3.9ms preprocess, 78.2ms inference, 2.6ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","74\n","\n","0: 416x640 3 buns, 1 thit-heo, 2 cha-coms, 1 doi-sun, 2 dau-hus, 212.9ms\n","Speed: 3.3ms preprocess, 212.9ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","75\n","\n","0: 640x640 2 buns, 7 thit-heos, 3 cha-coms, 1 doi-sun, 1 dau-hu, 101.3ms\n","Speed: 4.2ms preprocess, 101.3ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","76\n","\n","0: 640x608 1 bun, 1 thit-heo, 1 cha-com, 3 dau-hus, 81.5ms\n","Speed: 19.3ms preprocess, 81.5ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","77\n","\n","0: 640x640 1 bun, 4 thit-heos, 3 cha-coms, 1 doi-sun, 9 dau-hus, 4 cha-gios, 82.2ms\n","Speed: 21.3ms preprocess, 82.2ms inference, 11.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","78\n","\n","0: 608x640 1 bun, 1 thit-heo, 3 cha-coms, 6 dau-hus, 91.3ms\n","Speed: 14.9ms preprocess, 91.3ms inference, 1.7ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","79\n","\n","0: 480x640 1 bun, 6 thit-heos, 1 cha-com, 1 dau-hu, 88.5ms\n","Speed: 6.0ms preprocess, 88.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","80\n","\n","0: 640x640 1 bun, 1 thit-heo, 1 cha-com, 2 doi-suns, 7 dau-hus, 122.9ms\n","Speed: 25.6ms preprocess, 122.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","81\n","\n","0: 640x608 1 bun, 11 thit-heos, 2 cha-coms, 1 dau-hu, 105.2ms\n","Speed: 8.9ms preprocess, 105.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","82\n","\n","0: 640x416 1 bun, 1 thit-heo, 3 cha-coms, 1 doi-sun, 1 dau-hu, 488.7ms\n","Speed: 3.3ms preprocess, 488.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 416)\n","------\n","83\n","\n","0: 448x640 4 buns, 2 thit-heos, 2 cha-coms, 1 doi-sun, 1 dau-hu, 83.5ms\n","Speed: 3.5ms preprocess, 83.5ms inference, 8.1ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","84\n","\n","0: 416x640 1 bun, 1 thit-heo, 1 doi-sun, 4 dau-hus, 72.1ms\n","Speed: 3.0ms preprocess, 72.1ms inference, 3.2ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","85\n","\n","0: 448x640 13 buns, 6 thit-heos, 4 cha-coms, 13 dau-hus, 5 cha-gios, 72.2ms\n","Speed: 3.9ms preprocess, 72.2ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","86\n","\n","0: 640x640 2 buns, 3 thit-heos, 2 cha-coms, 3 doi-suns, 2 dau-hus, 2 cha-gios, 112.8ms\n","Speed: 4.9ms preprocess, 112.8ms inference, 25.8ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","87\n","\n","0: 640x640 3 buns, 4 thit-heos, 1 thit-heo-quay, 1 cha-com, 4 doi-suns, 3 dau-hus, 3 cha-gios, 110.0ms\n","Speed: 5.9ms preprocess, 110.0ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","88\n","\n","0: 480x640 1 bun, 1 thit-heo, 3 cha-coms, 2 dau-hus, 74.7ms\n","Speed: 1.7ms preprocess, 74.7ms inference, 5.4ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","89\n","\n","0: 512x640 6 buns, 4 cha-coms, 1 doi-sun, 8 dau-hus, 75.7ms\n","Speed: 3.4ms preprocess, 75.7ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","90\n","\n","0: 512x640 1 bun, 1 thit-heo, 2 cha-coms, 1 doi-sun, 3 dau-hus, 74.5ms\n","Speed: 4.4ms preprocess, 74.5ms inference, 2.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","91\n","\n","0: 640x576 4 buns, 4 cha-coms, 96.4ms\n","Speed: 4.2ms preprocess, 96.4ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","92\n","\n","0: 608x640 1 bun, 1 gan, 1 cha-com, 6 dau-hus, 3 cha-gios, 82.9ms\n","Speed: 4.5ms preprocess, 82.9ms inference, 2.0ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","93\n","\n","0: 640x640 3 buns, 1 thit-heo, 5 cha-coms, 4 dau-hus, 84.3ms\n","Speed: 1.9ms preprocess, 84.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","94\n","\n","0: 608x640 9 thit-heos, 3 cha-coms, 1 doi-sun, 13 dau-hus, 78.0ms\n","Speed: 4.2ms preprocess, 78.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","95\n","\n","0: 512x640 1 bun, 6 thit-heos, 1 cha-com, 2 dau-hus, 4 cha-gios, 61.9ms\n","Speed: 3.4ms preprocess, 61.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","96\n","\n","0: 640x640 2 toms, 1 trung, 3 tom-tits, 2 mucs, 98.0ms\n","Speed: 4.2ms preprocess, 98.0ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","97\n","\n","0: 512x640 4 buns, 3 tom-tits, 3 dau-hus, 63.1ms\n","Speed: 5.3ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","98\n","\n","0: 608x640 1 ca, 3 toms, 3 tom-tits, 3 mucs, 3 dau-hus, 80.4ms\n","Speed: 3.6ms preprocess, 80.4ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","99\n","\n","0: 512x640 1 bun, 3 tom-tits, 63.1ms\n","Speed: 5.2ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","100\n","\n","0: 480x640 4 toms, 4 tom-tits, 2 mucs, 3 dau-hus, 65.8ms\n","Speed: 2.8ms preprocess, 65.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","101\n","\n","0: 480x640 1 thit-heo, 5 tom-tits, 6 mucs, 1 dau-hu, 74.1ms\n","Speed: 2.8ms preprocess, 74.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","102\n","\n","0: 320x640 1 bun, 1 tom, 1 tom-tit, 2 dau-hus, 74.4ms\n","Speed: 3.6ms preprocess, 74.4ms inference, 1.3ms postprocess per image at shape (1, 3, 320, 640)\n","------\n","103\n","\n","0: 448x640 3 buns, 3 toms, 3 tom-tits, 71.8ms\n","Speed: 3.8ms preprocess, 71.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","104\n","\n","0: 352x640 3 buns, 1 tom, 3 tom-tits, 1 muc, 112.9ms\n","Speed: 2.6ms preprocess, 112.9ms inference, 1.8ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","105\n","\n","0: 576x640 3 cas, 2 toms, 4 thit-bos, 3 tom-tits, 1 muc, 2 dau-hus, 91.7ms\n","Speed: 5.1ms preprocess, 91.7ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","106\n","\n","0: 544x640 3 cas, 3 buns, 3 toms, 2 tom-tits, 81.2ms\n","Speed: 4.6ms preprocess, 81.2ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","107\n","\n","0: 448x640 1 bun, 6 tom-tits, 65.4ms\n","Speed: 2.5ms preprocess, 65.4ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","108\n","\n","0: 640x640 1 ca, 3 buns, 1 tom, 1 tom-tit, 2 mucs, 4 dau-hus, 88.6ms\n","Speed: 4.0ms preprocess, 88.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","109\n","\n","0: 448x640 3 buns, 1 tom, 1 tom-tit, 2 mucs, 59.1ms\n","Speed: 2.6ms preprocess, 59.1ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","110\n","\n","0: 640x640 1 ca, 2 buns, 3 toms, 2 tom-tits, 4 dau-hus, 80.8ms\n","Speed: 3.8ms preprocess, 80.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","111\n","\n","0: 640x576 6 buns, 1 tom, 1 tom-tit, 1 muc, 1 dau-hu, 76.9ms\n","Speed: 3.9ms preprocess, 76.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","112\n","\n","0: 608x640 2 buns, 1 tom-tit, 2 dau-hus, 77.9ms\n","Speed: 4.0ms preprocess, 77.9ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","113\n","\n","0: 512x640 1 bun, 2 toms, 1 tom-tit, 2 mucs, 5 dau-hus, 68.9ms\n","Speed: 4.2ms preprocess, 68.9ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","114\n","\n","0: 576x640 2 cas, 2 toms, 2 tom-tits, 2 mucs, 88.3ms\n","Speed: 3.7ms preprocess, 88.3ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","115\n","\n","0: 416x640 2 toms, 2 tom-tits, 2 mucs, 5 dau-hus, 70.7ms\n","Speed: 3.3ms preprocess, 70.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","116\n","\n","0: 576x640 2 toms, 3 tom-tits, 90.9ms\n","Speed: 3.9ms preprocess, 90.9ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","117\n","\n","0: 640x544 1 bun, 8 tom-tits, 95.7ms\n","Speed: 4.3ms preprocess, 95.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n","------\n","118\n","\n","0: 640x640 2 buns, 1 tom, 3 tom-tits, 3 mucs, 86.5ms\n","Speed: 4.6ms preprocess, 86.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","119\n","\n","0: 640x640 1 bun, 4 tom-tits, 4 dau-hus, 85.7ms\n","Speed: 5.6ms preprocess, 85.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","120\n","\n","0: 480x640 4 buns, 3 toms, 5 tom-tits, 2 mucs, 65.9ms\n","Speed: 3.3ms preprocess, 65.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","121\n","\n","0: 448x640 2 cas, 1 bun, 2 toms, 2 tom-tits, 2 mucs, 6 dau-hus, 65.7ms\n","Speed: 3.1ms preprocess, 65.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","122\n","\n","0: 640x640 1 ca, 2 buns, 1 tom, 1 tom-tit, 2 mucs, 3 dau-hus, 97.3ms\n","Speed: 4.5ms preprocess, 97.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","123\n","\n","0: 640x448 4 buns, 1 tom, 3 tom-tits, 69.5ms\n","Speed: 4.6ms preprocess, 69.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n","------\n","124\n","\n","0: 480x640 1 bun, 1 tom, 2 tom-tits, 3 mucs, 74.0ms\n","Speed: 4.2ms preprocess, 74.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","125\n","\n","0: 448x640 1 bun, 3 tom-tits, 3 dau-hus, 70.5ms\n","Speed: 1.6ms preprocess, 70.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","126\n","\n","0: 640x640 2 thit-heos, 3 vien-mocs, 93.6ms\n","Speed: 5.0ms preprocess, 93.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","127\n","\n","0: 640x640 2 thit-heos, 4 vien-mocs, 85.6ms\n","Speed: 3.9ms preprocess, 85.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","128\n","\n","0: 544x640 1 bun, 4 vien-mocs, 78.2ms\n","Speed: 3.9ms preprocess, 78.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","129\n","\n","0: 544x640 2 buns, 1 thit-heo, 5 vien-mocs, 76.8ms\n","Speed: 3.4ms preprocess, 76.8ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","130\n","\n","0: 480x640 1 bun, 2 thit-heos, 12 vien-mocs, 64.8ms\n","Speed: 5.6ms preprocess, 64.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","131\n","\n","0: 640x576 1 bun, 2 thit-heos, 5 vien-mocs, 84.2ms\n","Speed: 3.8ms preprocess, 84.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","132\n","\n","0: 416x640 2 buns, 5 vien-mocs, 60.3ms\n","Speed: 3.9ms preprocess, 60.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","133\n","\n","0: 512x640 6 vien-mocs, 64.4ms\n","Speed: 5.3ms preprocess, 64.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","134\n","\n","0: 480x640 6 thit-heos, 2 vien-mocs, 63.3ms\n","Speed: 2.8ms preprocess, 63.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","135\n","\n","0: 640x640 1 bun, 2 thit-heos, 2 vien-mocs, 83.7ms\n","Speed: 3.2ms preprocess, 83.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","136\n","\n","0: 480x640 1 bun, 2 thit-heos, 5 vien-mocs, 65.5ms\n","Speed: 1.5ms preprocess, 65.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","137\n","\n","0: 608x640 2 buns, 2 thit-heos, 4 vien-mocs, 95.5ms\n","Speed: 2.9ms preprocess, 95.5ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","138\n","\n","0: 640x640 3 buns, 7 vien-mocs, 85.3ms\n","Speed: 3.4ms preprocess, 85.3ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","139\n","\n","0: 480x640 3 vien-mocs, 62.1ms\n","Speed: 2.6ms preprocess, 62.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","140\n","\n","0: 640x640 1 bun, 5 vien-mocs, 80.9ms\n","Speed: 3.6ms preprocess, 80.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","141\n","\n","0: 544x640 4 buns, 4 vien-mocs, 74.0ms\n","Speed: 2.8ms preprocess, 74.0ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","142\n","\n","0: 416x640 1 bun, 4 vien-mocs, 60.4ms\n","Speed: 3.2ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","143\n","\n","0: 480x640 2 buns, 3 vien-mocs, 61.7ms\n","Speed: 2.2ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","144\n","\n","0: 608x640 5 thit-heos, 2 vien-mocs, 94.4ms\n","Speed: 4.0ms preprocess, 94.4ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","145\n","\n","0: 640x608 1 bun, 1 muc, 95.9ms\n","Speed: 4.6ms preprocess, 95.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","146\n","\n","0: 544x640 3 buns, 1 trung, 6 mucs, 89.6ms\n","Speed: 4.4ms preprocess, 89.6ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","147\n","\n","0: 448x640 1 ca, 1 bun, 3 mucs, 71.6ms\n","Speed: 4.0ms preprocess, 71.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","148\n","\n","0: 544x640 1 bun, 2 mucs, 89.6ms\n","Speed: 3.8ms preprocess, 89.6ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","149\n","\n","0: 512x640 8 mucs, 3 vien-mocs, 67.5ms\n","Speed: 4.1ms preprocess, 67.5ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","150\n","\n","0: 640x640 5 buns, 4 mucs, 88.3ms\n","Speed: 4.0ms preprocess, 88.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","151\n","\n","0: 640x640 3 buns, 6 mucs, 81.1ms\n","Speed: 3.8ms preprocess, 81.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","152\n","\n","0: 608x640 1 bun, 2 trungs, 4 mucs, 77.6ms\n","Speed: 5.2ms preprocess, 77.6ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","153\n","\n","0: 512x640 3 buns, 6 mucs, 62.4ms\n","Speed: 3.7ms preprocess, 62.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","154\n","\n","0: 544x640 3 buns, 3 mucs, 73.7ms\n","Speed: 4.0ms preprocess, 73.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","155\n","\n","0: 384x640 1 tom, 3 mucs, 51.6ms\n","Speed: 3.7ms preprocess, 51.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","156\n","\n","0: 640x640 1 bun, 5 mucs, 97.3ms\n","Speed: 4.2ms preprocess, 97.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","157\n","\n","0: 608x640 1 muc, 79.2ms\n","Speed: 4.3ms preprocess, 79.2ms inference, 2.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","158\n","\n","0: 384x640 1 tom, 1 thit-heo-quay, 53.0ms\n","Speed: 1.8ms preprocess, 53.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","159\n","\n","0: 640x640 4 cas, 3 buns, 4 toms, 4 thit-heo-quays, 81.9ms\n","Speed: 4.3ms preprocess, 81.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","160\n","\n","0: 640x576 1 ca, 2 buns, 2 toms, 2 thit-heo-quays, 78.5ms\n","Speed: 2.8ms preprocess, 78.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","161\n","\n","0: 640x640 1 ca, 1 bun, 2 toms, 3 thit-heo-quays, 96.2ms\n","Speed: 2.7ms preprocess, 96.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","162\n","\n","0: 640x640 2 cas, 2 buns, 2 toms, 3 thit-heo-quays, 85.6ms\n","Speed: 2.9ms preprocess, 85.6ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","163\n","\n","0: 512x640 1 ca, 3 buns, 1 tom, 4 thit-heo-quays, 62.9ms\n","Speed: 3.6ms preprocess, 62.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","164\n","\n","0: 576x640 2 cas, 2 buns, 2 toms, 3 thit-heo-quays, 75.0ms\n","Speed: 3.5ms preprocess, 75.0ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","165\n","\n","0: 512x640 1 ca, 2 toms, 5 thit-heo-quays, 61.9ms\n","Speed: 2.6ms preprocess, 61.9ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","166\n","\n","0: 640x640 1 ca, 2 buns, 1 hu-tieu, 2 toms, 3 thit-heo-quays, 80.7ms\n","Speed: 3.7ms preprocess, 80.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","167\n","\n","0: 480x640 2 cas, 3 buns, 4 toms, 4 thit-heo-quays, 72.6ms\n","Speed: 5.9ms preprocess, 72.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","168\n","\n","0: 640x640 1 ca, 3 toms, 1 thit-heo, 1 gan, 3 thit-heo-quays, 98.6ms\n","Speed: 3.8ms preprocess, 98.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","169\n","\n","0: 480x640 2 cas, 2 buns, 3 toms, 62.6ms\n","Speed: 3.4ms preprocess, 62.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","170\n","\n","0: 448x640 1 ca, 2 toms, 3 thit-heo-quays, 60.6ms\n","Speed: 2.7ms preprocess, 60.6ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","171\n","\n","0: 416x640 3 cas, 2 buns, 2 thit-heo-quays, 2 rau-rams, 59.9ms\n","Speed: 2.7ms preprocess, 59.9ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","172\n","\n","0: 640x576 2 buns, 1 thit-heo-quay, 3 rau-rams, 81.2ms\n","Speed: 3.2ms preprocess, 81.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","173\n","\n","0: 448x640 3 cas, 3 thit-heo-quays, 61.7ms\n","Speed: 2.5ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","174\n","\n","0: 640x512 2 cas, 1 bun, 1 tom, 2 thit-heo-quays, 3 rau-rams, 78.5ms\n","Speed: 2.8ms preprocess, 78.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 512)\n","------\n","175\n","\n","0: 576x640 1 ca, 1 bun, 2 toms, 2 thit-heo-quays, 91.0ms\n","Speed: 4.0ms preprocess, 91.0ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","176\n","\n","0: 544x640 1 ca, 1 bun, 2 toms, 3 thit-heo-quays, 90.3ms\n","Speed: 3.5ms preprocess, 90.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","177\n","\n","0: 576x640 2 cas, 3 toms, 3 thit-heos, 1 rau-ram, 93.7ms\n","Speed: 2.8ms preprocess, 93.7ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","178\n","\n","0: 480x640 2 cas, 3 buns, 2 toms, 4 thit-heo-quays, 1 rau-ram, 74.1ms\n","Speed: 3.0ms preprocess, 74.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","179\n","\n","0: 640x608 3 cas, 2 buns, 3 toms, 95.0ms\n","Speed: 3.3ms preprocess, 95.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","180\n","\n","0: 608x640 1 tom, 2 thit-heo-quays, 94.8ms\n","Speed: 2.7ms preprocess, 94.8ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","181\n","\n","0: 416x640 1 ca, 1 bun, 2 toms, 3 thit-heo-quays, 70.6ms\n","Speed: 2.9ms preprocess, 70.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","182\n","\n","0: 448x640 5 cas, 1 bun, 1 tom, 4 thit-heo-quays, 71.7ms\n","Speed: 2.3ms preprocess, 71.7ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","183\n","\n","0: 608x640 2 cas, 1 bun, 2 toms, 3 thit-heo-quays, 1 rau-ram, 95.0ms\n","Speed: 4.1ms preprocess, 95.0ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","184\n","\n","0: 608x640 3 thit-heos, 1 mi, 2 banh-das, 93.5ms\n","Speed: 3.7ms preprocess, 93.5ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","185\n","\n","0: 384x640 5 thit-heos, 2 mis, 1 banh-da, 54.5ms\n","Speed: 3.4ms preprocess, 54.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","186\n","\n","0: 640x416 4 thit-heos, 3 mis, 5 banh-das, 62.5ms\n","Speed: 4.0ms preprocess, 62.5ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 416)\n","------\n","187\n","\n","0: 448x640 4 thit-heos, 4 mis, 5 banh-das, 62.9ms\n","Speed: 4.0ms preprocess, 62.9ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","188\n","\n","0: 640x640 5 thit-heos, 3 mis, 5 banh-das, 85.2ms\n","Speed: 4.6ms preprocess, 85.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","189\n","\n","0: 544x640 2 thit-heos, 1 mi, 9 banh-das, 75.1ms\n","Speed: 4.2ms preprocess, 75.1ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","190\n","\n","0: 640x640 4 thit-heos, 3 mis, 3 banh-das, 82.1ms\n","Speed: 3.2ms preprocess, 82.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","191\n","\n","0: 576x640 6 thit-heos, 2 mis, 5 banh-das, 77.1ms\n","Speed: 4.1ms preprocess, 77.1ms inference, 1.5ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","192\n","\n","0: 640x640 4 thit-heos, 3 mis, 5 banh-das, 82.2ms\n","Speed: 4.4ms preprocess, 82.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","193\n","\n","0: 416x640 2 thit-heos, 1 mi, 3 banh-das, 58.0ms\n","Speed: 3.1ms preprocess, 58.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","194\n","\n","0: 640x512 6 thit-heos, 2 mis, 8 banh-das, 61.7ms\n","Speed: 3.5ms preprocess, 61.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n","------\n","195\n","\n","0: 480x640 4 thit-heos, 3 mis, 3 banh-das, 61.1ms\n","Speed: 3.8ms preprocess, 61.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","196\n","\n","0: 576x640 4 thit-heos, 2 mis, 4 banh-das, 75.5ms\n","Speed: 3.3ms preprocess, 75.5ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","197\n","\n","0: 608x640 5 mis, 6 banh-das, 83.1ms\n","Speed: 3.3ms preprocess, 83.1ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","198\n","\n","0: 448x640 4 thit-heos, 1 mi, 6 banh-das, 73.4ms\n","Speed: 2.6ms preprocess, 73.4ms inference, 2.0ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","199\n","\n","0: 352x640 1 thit-heo, 1 mi, 62.4ms\n","Speed: 4.4ms preprocess, 62.4ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","200\n","\n","0: 480x640 3 thit-heos, 2 mis, 3 banh-das, 74.5ms\n","Speed: 3.8ms preprocess, 74.5ms inference, 6.2ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","201\n","\n","0: 576x640 5 thit-heos, 3 mis, 5 banh-das, 91.3ms\n","Speed: 5.8ms preprocess, 91.3ms inference, 1.7ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","202\n","\n","0: 416x640 5 thit-heos, 1 mi, 8 banh-das, 71.3ms\n","Speed: 3.0ms preprocess, 71.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","203\n","\n","0: 544x640 3 thit-heos, 3 mis, 6 banh-das, 90.2ms\n","Speed: 3.0ms preprocess, 90.2ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","204\n","\n","0: 416x640 3 thit-heos, 1 mi, 3 banh-das, 73.1ms\n","Speed: 3.3ms preprocess, 73.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","205\n","\n","0: 512x640 4 thit-heos, 2 mis, 4 banh-das, 76.0ms\n","Speed: 3.5ms preprocess, 76.0ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","206\n","\n","0: 544x640 4 thit-heos, 1 mi, 7 banh-das, 89.6ms\n","Speed: 3.8ms preprocess, 89.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","207\n","\n","0: 384x640 3 thit-heos, 2 mis, 5 banh-das, 56.6ms\n","Speed: 2.7ms preprocess, 56.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","208\n","\n","0: 640x640 3 thit-heos, 3 mis, 3 banh-das, 88.4ms\n","Speed: 3.1ms preprocess, 88.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","209\n","\n","0: 512x640 3 thit-heos, 3 mis, 7 banh-das, 62.0ms\n","Speed: 3.0ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","210\n","\n","0: 544x640 2 thit-heos, 2 mis, 4 banh-das, 74.0ms\n","Speed: 3.3ms preprocess, 74.0ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","211\n","\n","0: 640x576 1 thit-heo, 2 mis, 2 banh-das, 76.8ms\n","Speed: 4.5ms preprocess, 76.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","212\n","\n","0: 640x608 2 thit-heos, 1 mi, 2 banh-das, 77.9ms\n","Speed: 3.6ms preprocess, 77.9ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","213\n","\n","0: 576x640 2 mis, 3 banh-das, 81.3ms\n","Speed: 3.5ms preprocess, 81.3ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","214\n","\n","0: 448x640 4 thit-heos, 1 mi, 4 banh-das, 70.8ms\n","Speed: 2.7ms preprocess, 70.8ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","215\n","\n","0: 352x640 3 thit-heos, 2 mis, 62.3ms\n","Speed: 2.3ms preprocess, 62.3ms inference, 1.2ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","216\n","\n","0: 416x640 4 thit-heos, 1 mi, 4 banh-das, 70.6ms\n","Speed: 3.1ms preprocess, 70.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","217\n","\n","0: 448x640 1 thit-heo, 1 mi, 5 banh-das, 72.0ms\n","Speed: 3.0ms preprocess, 72.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","218\n","\n","0: 448x640 2 thit-heos, 2 mis, 3 banh-das, 70.9ms\n","Speed: 3.8ms preprocess, 70.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","219\n","\n","0: 640x640 1 mi, 2 banh-das, 97.9ms\n","Speed: 3.7ms preprocess, 97.9ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","220\n","\n","0: 448x640 4 thit-heos, 1 mi, 4 banh-das, 72.1ms\n","Speed: 2.7ms preprocess, 72.1ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","221\n","\n","0: 448x640 2 coms, 6 thit-gas, 3 rau-rams, 70.9ms\n","Speed: 3.2ms preprocess, 70.9ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","222\n","\n","0: 640x640 3 trungs, 1 com, 2 thit-gas, 3 rau-rams, 98.3ms\n","Speed: 4.2ms preprocess, 98.3ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","223\n","\n","0: 576x640 1 com, 1 thit-ga, 2 rau-rams, 76.7ms\n","Speed: 5.3ms preprocess, 76.7ms inference, 2.4ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","224\n","\n","0: 640x640 1 com, 3 thit-gas, 1 rau-ram, 82.2ms\n","Speed: 5.0ms preprocess, 82.2ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","225\n","\n","0: 448x640 1 com, 3 thit-gas, 59.6ms\n","Speed: 3.2ms preprocess, 59.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","226\n","\n","0: 640x640 1 com, 2 thit-gas, 1 rau-ram, 81.1ms\n","Speed: 4.1ms preprocess, 81.1ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","227\n","\n","0: 448x640 1 trung, 2 coms, 3 thit-gas, 60.2ms\n","Speed: 3.1ms preprocess, 60.2ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","228\n","\n","0: 640x608 1 com, 1 thit-ga, 1 rau-ram, 78.1ms\n","Speed: 6.1ms preprocess, 78.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","229\n","\n","0: 640x640 4 coms, 1 suon, 3 thit-gas, 1 rau-ram, 90.8ms\n","Speed: 5.3ms preprocess, 90.8ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","230\n","\n","0: 640x640 2 coms, 3 thit-gas, 5 rau-rams, 79.7ms\n","Speed: 4.2ms preprocess, 79.7ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","231\n","\n","0: 640x640 2 thit-gas, 1 rau-ram, 79.7ms\n","Speed: 3.2ms preprocess, 79.7ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","232\n","\n","0: 640x640 8 trungs, 1 com, 1 thit-ga, 1 rau-ram, 79.7ms\n","Speed: 6.4ms preprocess, 79.7ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","233\n","\n","0: 544x640 1 com, 2 thit-gas, 1 rau-ram, 76.3ms\n","Speed: 4.0ms preprocess, 76.3ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","234\n","\n","0: 640x640 1 com, 1 thit-ga, 2 rau-rams, 91.9ms\n","Speed: 3.8ms preprocess, 91.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","235\n","\n","0: 544x640 3 coms, 3 thit-gas, 1 rau-ram, 75.2ms\n","Speed: 2.7ms preprocess, 75.2ms inference, 2.0ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","236\n","\n","0: 512x640 9 trungs, 1 com, 1 thit-ga, 1 rau-ram, 64.2ms\n","Speed: 4.0ms preprocess, 64.2ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","237\n","\n","0: 512x640 5 coms, 4 thit-gas, 1 rau-ram, 62.2ms\n","Speed: 3.2ms preprocess, 62.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","238\n","\n","0: 448x640 2 coms, 2 thit-gas, 1 rau-ram, 60.6ms\n","Speed: 3.2ms preprocess, 60.6ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","239\n","\n","0: 640x640 1 trung, 1 com, 3 thit-gas, 2 rau-rams, 89.9ms\n","Speed: 3.7ms preprocess, 89.9ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","240\n","\n","0: 480x640 3 coms, 4 thit-gas, 76.8ms\n","Speed: 2.9ms preprocess, 76.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","241\n","\n","0: 640x544 1 com, 6 thit-gas, 1 rau-ram, 92.6ms\n","Speed: 3.3ms preprocess, 92.6ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 544)\n","------\n","242\n","\n","0: 640x640 3 coms, 8 thit-gas, 4 rau-rams, 86.6ms\n","Speed: 3.4ms preprocess, 86.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","243\n","\n","0: 512x640 1 com, 1 thit-ga, 2 rau-rams, 66.4ms\n","Speed: 4.4ms preprocess, 66.4ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","244\n","\n","0: 480x640 1 com, 2 thit-gas, 1 rau-ram, 65.8ms\n","Speed: 3.6ms preprocess, 65.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","245\n","\n","0: 544x640 1 com, 1 thit-ga, 2 rau-rams, 79.4ms\n","Speed: 2.9ms preprocess, 79.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","246\n","\n","0: 576x640 1 com, 1 thit-ga, 91.1ms\n","Speed: 3.3ms preprocess, 91.1ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","247\n","\n","0: 576x640 3 coms, 2 thit-gas, 90.0ms\n","Speed: 3.8ms preprocess, 90.0ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","248\n","\n","0: 448x640 3 coms, 1 thit-ga, 1 rau-ram, 70.4ms\n","Speed: 2.6ms preprocess, 70.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","249\n","\n","0: 480x640 1 com, 1 thit-ga, 2 rau-rams, 74.0ms\n","Speed: 3.0ms preprocess, 74.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","250\n","\n","0: 512x640 6 coms, 6 thit-gas, 73.4ms\n","Speed: 4.3ms preprocess, 73.4ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","251\n","\n","0: 448x640 2 coms, 6 thit-gas, 2 rau-rams, 70.2ms\n","Speed: 2.9ms preprocess, 70.2ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","252\n","\n","0: 544x640 2 coms, 4 thit-gas, 1 rau-ram, 89.9ms\n","Speed: 5.0ms preprocess, 89.9ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","253\n","\n","0: 640x640 1 com, 2 thit-gas, 1 rau-ram, 90.6ms\n","Speed: 3.1ms preprocess, 90.6ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","254\n","\n","0: 640x640 1 com, 4 thit-gas, 4 rau-rams, 79.7ms\n","Speed: 4.1ms preprocess, 79.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","255\n","\n","0: 544x640 1 com, 4 thit-gas, 2 rau-rams, 1 mi, 73.8ms\n","Speed: 3.1ms preprocess, 73.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","256\n","\n","0: 544x640 4 coms, 5 thit-gas, 2 rau-rams, 72.8ms\n","Speed: 5.9ms preprocess, 72.8ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","257\n","\n","0: 576x640 1 com, 3 thit-gas, 1 rau-ram, 74.9ms\n","Speed: 3.2ms preprocess, 74.9ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","258\n","\n","0: 512x640 1 com, 6 thit-gas, 4 rau-rams, 75.6ms\n","Speed: 4.8ms preprocess, 75.6ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","259\n","\n","0: 640x608 1 com, 1 thit-ga, 96.9ms\n","Speed: 3.2ms preprocess, 96.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 608)\n","------\n","260\n","\n","0: 640x640 8 trungs, 6 coms, 8 thit-gas, 5 rau-rams, 98.3ms\n","Speed: 3.7ms preprocess, 98.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","261\n","\n","0: 480x640 2 trungs, 1 dua-chua, 4 coms, 1 suon, 74.8ms\n","Speed: 3.0ms preprocess, 74.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","262\n","\n","0: 608x640 1 thit-heo, 3 trungs, 2 dua-chuas, 3 coms, 5 suons, 1 bi, 95.0ms\n","Speed: 6.0ms preprocess, 95.0ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","263\n","\n","0: 448x640 2 trungs, 1 dua-chua, 1 com, 1 suon, 1 bi, 63.1ms\n","Speed: 3.0ms preprocess, 63.1ms inference, 1.8ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","264\n","\n","0: 384x640 1 trung, 1 dua-chua, 1 com, 1 suon, 1 bi, 54.6ms\n","Speed: 5.2ms preprocess, 54.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","265\n","\n","0: 576x640 1 trung, 1 dua-chua, 1 com, 2 suons, 1 bi, 79.4ms\n","Speed: 3.3ms preprocess, 79.4ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","266\n","\n","0: 416x640 1 trung, 1 dua-chua, 1 com, 1 suon, 1 bi, 61.8ms\n","Speed: 2.7ms preprocess, 61.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","267\n","\n","0: 480x640 2 trungs, 4 dua-chuas, 2 coms, 4 suons, 71.1ms\n","Speed: 4.0ms preprocess, 71.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","268\n","\n","0: 608x640 1 trung, 1 com, 1 suon, 95.8ms\n","Speed: 5.1ms preprocess, 95.8ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","269\n","\n","0: 448x640 5 trungs, 2 dua-chuas, 4 coms, 2 suons, 1 bi, 70.3ms\n","Speed: 2.8ms preprocess, 70.3ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","270\n","\n","0: 512x640 2 trungs, 1 com, 1 suon, 1 bi, 73.7ms\n","Speed: 5.0ms preprocess, 73.7ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","271\n","\n","0: 576x640 1 dua-chua, 1 com, 1 suon, 89.3ms\n","Speed: 4.5ms preprocess, 89.3ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","272\n","\n","0: 352x640 2 trungs, 1 dua-chua, 1 com, 2 suons, 1 bi, 56.4ms\n","Speed: 2.6ms preprocess, 56.4ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","273\n","\n","0: 608x640 2 trungs, 1 com, 1 suon, 2 bis, 85.1ms\n","Speed: 3.4ms preprocess, 85.1ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","274\n","\n","0: 512x640 1 trung, 3 coms, 1 suon, 64.2ms\n","Speed: 3.7ms preprocess, 64.2ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","275\n","\n","0: 352x640 1 com, 1 suon, 54.3ms\n","Speed: 2.3ms preprocess, 54.3ms inference, 1.3ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","276\n","\n","0: 640x544 1 dua-chua, 3 coms, 1 suon, 79.2ms\n","Speed: 3.2ms preprocess, 79.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 544)\n","------\n","277\n","\n","0: 640x448 1 trung, 1 dua-chua, 1 com, 1 suon, 1 bi, 73.8ms\n","Speed: 3.1ms preprocess, 73.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n","------\n","278\n","\n","0: 480x640 2 trungs, 1 dua-chua, 3 suons, 75.1ms\n","Speed: 3.0ms preprocess, 75.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","279\n","\n","0: 416x640 1 dua-chua, 1 com, 1 suon, 70.6ms\n","Speed: 2.6ms preprocess, 70.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","280\n","\n","0: 608x640 1 trung, 1 dua-chua, 1 com, 1 suon, 94.6ms\n","Speed: 5.6ms preprocess, 94.6ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","281\n","\n","0: 640x512 3 trungs, 4 dua-chuas, 4 coms, 3 suons, 65.2ms\n","Speed: 3.9ms preprocess, 65.2ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n","------\n","282\n","\n","0: 384x640 2 trungs, 1 dua-chua, 1 com, 2 suons, 1 bi, 54.4ms\n","Speed: 2.4ms preprocess, 54.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","283\n","\n","0: 384x640 1 trung, 1 com, 1 suon, 53.6ms\n","Speed: 3.5ms preprocess, 53.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","284\n","\n","0: 416x640 3 trungs, 1 dua-chua, 1 com, 1 suon, 1 bi, 61.2ms\n","Speed: 3.3ms preprocess, 61.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","285\n","\n","0: 416x640 1 trung, 1 dua-chua, 1 com, 1 suon, 1 bi, 70.4ms\n","Speed: 2.9ms preprocess, 70.4ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","286\n","\n","0: 544x640 1 trung, 1 com, 2 suons, 1 bi, 89.8ms\n","Speed: 4.0ms preprocess, 89.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","287\n","\n","0: 480x640 1 dua-chua, 1 com, 1 suon, 67.5ms\n","Speed: 6.1ms preprocess, 67.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","288\n","\n","0: 608x640 1 trung, 1 dua-chua, 5 coms, 1 suon, 85.7ms\n","Speed: 4.9ms preprocess, 85.7ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","289\n","\n","0: 512x640 2 trungs, 3 coms, 1 suon, 64.4ms\n","Speed: 1.9ms preprocess, 64.4ms inference, 1.6ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","290\n","\n","0: 640x576 2 trungs, 1 dua-chua, 1 com, 1 suon, 80.7ms\n","Speed: 3.3ms preprocess, 80.7ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","291\n","\n","0: 512x640 2 trungs, 1 dua-chua, 1 com, 1 suon, 1 bi, 64.1ms\n","Speed: 3.4ms preprocess, 64.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","292\n","\n","0: 640x640 1 trung, 1 com, 1 suon, 1 bi, 97.7ms\n","Speed: 4.7ms preprocess, 97.7ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","293\n","\n","0: 640x640 10 trungs, 1 com, 1 suon, 81.2ms\n","Speed: 6.2ms preprocess, 81.2ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","294\n","\n","0: 544x640 1 com, 1 suon, 1 bi, 73.7ms\n","Speed: 4.1ms preprocess, 73.7ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","295\n","\n","0: 352x640 1 trung, 1 dua-chua, 1 suon, 1 bi, 52.2ms\n","Speed: 3.6ms preprocess, 52.2ms inference, 1.6ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","296\n","\n","0: 544x640 2 trungs, 1 dua-chua, 3 coms, 1 suon, 1 bi, 73.6ms\n","Speed: 3.2ms preprocess, 73.6ms inference, 1.2ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","297\n","\n","0: 416x640 1 hu-tieu, 2 toms, 7 thit-heos, 1 gan, 3 trungs, 1 thit-bam, 58.3ms\n","Speed: 3.1ms preprocess, 58.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","298\n","\n","0: 512x640 2 hu-tieus, 1 tom, 6 thit-heos, 1 gan, 1 thit-bam, 62.0ms\n","Speed: 3.8ms preprocess, 62.0ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","299\n","\n","0: 640x640 1 hu-tieu, 2 toms, 1 thit-heo, 3 gans, 1 thit-bam, 97.8ms\n","Speed: 4.1ms preprocess, 97.8ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","300\n","\n","0: 512x640 2 toms, 1 gan, 75.0ms\n","Speed: 2.8ms preprocess, 75.0ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","301\n","\n","0: 448x640 1 tom, 2 thit-heos, 1 gan, 71.7ms\n","Speed: 3.2ms preprocess, 71.7ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","302\n","\n","0: 640x640 1 hu-tieu, 1 tom, 5 thit-heos, 1 gan, 2 thit-bams, 98.8ms\n","Speed: 4.1ms preprocess, 98.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","303\n","\n","0: 608x640 2 toms, 3 thit-heos, 2 trungs, 78.9ms\n","Speed: 4.7ms preprocess, 78.9ms inference, 1.2ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","304\n","\n","0: 640x640 2 toms, 2 thit-heos, 2 gans, 1 trung, 1 thit-bam, 88.4ms\n","Speed: 7.6ms preprocess, 88.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","305\n","\n","0: 416x640 1 tom, 2 thit-heos, 2 mucs, 58.4ms\n","Speed: 2.9ms preprocess, 58.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","306\n","\n","0: 576x640 1 hu-tieu, 2 toms, 4 thit-heos, 3 trungs, 2 thit-bams, 75.4ms\n","Speed: 5.7ms preprocess, 75.4ms inference, 2.0ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","307\n","\n","0: 576x640 3 toms, 1 trung, 74.0ms\n","Speed: 3.1ms preprocess, 74.0ms inference, 3.9ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","308\n","\n","0: 608x640 2 toms, 2 thit-heos, 1 gan, 1 trung, 1 thit-bam, 84.4ms\n","Speed: 5.9ms preprocess, 84.4ms inference, 1.8ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","309\n","\n","0: 448x640 3 hu-tieus, 1 tom, 3 thit-heos, 1 gan, 1 trung, 65.5ms\n","Speed: 2.9ms preprocess, 65.5ms inference, 2.1ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","310\n","\n","0: 608x640 1 hu-tieu, 1 tom, 1 thit-heo, 1 gan, 2 mucs, 95.4ms\n","Speed: 4.6ms preprocess, 95.4ms inference, 2.1ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","311\n","\n","0: 416x640 3 toms, 2 thit-heos, 1 trung, 1 thit-bam, 2 mis, 61.6ms\n","Speed: 4.4ms preprocess, 61.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","312\n","\n","0: 640x640 1 tom, 1 trung, 2 mis, 85.2ms\n","Speed: 3.5ms preprocess, 85.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","313\n","\n","0: 480x640 2 banh-hois, 61.0ms\n","Speed: 3.5ms preprocess, 61.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","314\n","\n","0: 352x640 2 toms, 1 mi, 2 banh-das, 51.7ms\n","Speed: 2.0ms preprocess, 51.7ms inference, 1.5ms postprocess per image at shape (1, 3, 352, 640)\n","------\n","315\n","\n","0: 448x640 1 thit-heo, 1 trung, 1 mi, 59.9ms\n","Speed: 3.1ms preprocess, 59.9ms inference, 1.6ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","316\n","\n","0: 640x576 1 tom, 1 thit-heo, 1 thit-ga, 1 mi, 2 banh-das, 77.0ms\n","Speed: 6.6ms preprocess, 77.0ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n","------\n","317\n","\n","0: 640x640 1 rau-ram, 1 mi, 2 dau-hus, 90.4ms\n","Speed: 6.7ms preprocess, 90.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","318\n","\n","0: 608x640 1 tom, 4 thit-heos, 1 trung, 4 mis, 2 banh-das, 79.7ms\n","Speed: 4.2ms preprocess, 79.7ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","319\n","\n","0: 640x544 8 cas, 4 mis, 1 banh-da, 78.1ms\n","Speed: 4.2ms preprocess, 78.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 544)\n","------\n","320\n","\n","0: 608x640 2 cas, 2 toms, 1 trung, 2 mis, 3 banh-das, 80.4ms\n","Speed: 3.4ms preprocess, 80.4ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","321\n","\n","0: 416x640 1 trung, 1 mi, 1 banh-da, 59.1ms\n","Speed: 2.6ms preprocess, 59.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","322\n","\n","0: 448x640 3 toms, 1 mi, 72.3ms\n","Speed: 4.1ms preprocess, 72.3ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","323\n","\n","0: 576x640 1 tom, 4 thit-heos, 5 mis, 91.0ms\n","Speed: 3.2ms preprocess, 91.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","324\n","\n","0: 608x640 5 toms, 5 thit-heos, 4 trungs, 4 mis, 2 banh-das, 96.9ms\n","Speed: 5.8ms preprocess, 96.9ms inference, 1.4ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","325\n","\n","0: 448x640 3 toms, 2 thit-heos, 1 trung, 3 mis, 2 banh-das, 72.0ms\n","Speed: 3.6ms preprocess, 72.0ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","326\n","\n","0: 384x640 1 trung, 2 mis, 63.1ms\n","Speed: 3.0ms preprocess, 63.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","327\n","\n","0: 608x640 3 mis, 4 banh-das, 2 dau-hus, 94.8ms\n","Speed: 3.5ms preprocess, 94.8ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","328\n","\n","0: 416x640 4 thit-gas, 3 mis, 62.3ms\n","Speed: 2.7ms preprocess, 62.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","329\n","\n","0: 448x640 2 toms, 1 thit-heo, 1 trung, 1 mi, 62.6ms\n","Speed: 2.5ms preprocess, 62.6ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","330\n","\n","0: 448x640 2 toms, 2 thit-heos, 1 trung, 2 mis, 61.5ms\n","Speed: 2.9ms preprocess, 61.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","331\n","\n","0: 512x640 1 thit-heo, 1 trung, 1 mi, 65.2ms\n","Speed: 4.4ms preprocess, 65.2ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","332\n","\n","0: 576x640 1 tom, 1 thit-heo, 2 trungs, 4 mis, 3 banh-das, 79.9ms\n","Speed: 4.3ms preprocess, 79.9ms inference, 1.4ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","333\n","\n","0: 640x640 3 thit-heos, 2 mis, 2 banh-das, 98.0ms\n","Speed: 4.4ms preprocess, 98.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","334\n","\n","0: 640x640 3 thit-heos, 2 trungs, 3 mis, 96.9ms\n","Speed: 4.0ms preprocess, 96.9ms inference, 2.9ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","335\n","\n","0: 544x640 3 toms, 4 trungs, 2 thit-gas, 1 mi, 76.4ms\n","Speed: 3.7ms preprocess, 76.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","336\n","\n","0: 608x640 5 cas, 1 mi, 1 banh-da, 80.7ms\n","Speed: 4.0ms preprocess, 80.7ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","337\n","\n","0: 384x640 1 tom, 2 thit-gas, 3 mis, 53.7ms\n","Speed: 2.7ms preprocess, 53.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","------\n","338\n","\n","0: 544x640 1 thit-heo, 2 trungs, 1 thit-ga, 3 mis, 1 banh-da, 76.4ms\n","Speed: 3.5ms preprocess, 76.4ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","339\n","\n","0: 608x640 1 thit-ga, 5 mis, 93.6ms\n","Speed: 3.1ms preprocess, 93.6ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","340\n","\n","0: 576x640 1 ca, 1 tom, 2 trungs, 3 mis, 3 banh-das, 91.2ms\n","Speed: 4.7ms preprocess, 91.2ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","341\n","\n","0: 512x640 1 thit-ga, 4 mis, 75.3ms\n","Speed: 3.1ms preprocess, 75.3ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","342\n","\n","0: 576x640 1 tom, 2 thit-heos, 3 trungs, 5 thit-gas, 1 mi, 92.0ms\n","Speed: 3.7ms preprocess, 92.0ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","343\n","\n","0: 608x640 4 cas, 1 tom, 1 thit-heo, 2 trungs, 1 thit-ga, 4 mis, 2 banh-das, 88.0ms\n","Speed: 5.3ms preprocess, 88.0ms inference, 1.6ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","344\n","\n","0: 448x640 7 thit-bos, 1 pho, 62.5ms\n","Speed: 2.5ms preprocess, 62.5ms inference, 1.5ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","345\n","\n","0: 544x640 6 thit-bos, 2 phos, 77.9ms\n","Speed: 3.3ms preprocess, 77.9ms inference, 1.5ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","346\n","\n","0: 512x640 5 thit-bos, 4 phos, 65.4ms\n","Speed: 3.4ms preprocess, 65.4ms inference, 1.5ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","347\n","\n","0: 640x640 2 thit-bos, 2 phos, 85.6ms\n","Speed: 3.7ms preprocess, 85.6ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","348\n","\n","0: 640x640 9 thit-bos, 3 phos, 79.7ms\n","Speed: 4.1ms preprocess, 79.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","349\n","\n","0: 480x640 6 thit-bos, 1 trung, 2 phos, 61.4ms\n","Speed: 2.6ms preprocess, 61.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","350\n","\n","0: 480x640 2 thit-bos, 1 pho, 60.2ms\n","Speed: 3.0ms preprocess, 60.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","351\n","\n","0: 640x640 3 thit-bos, 3 phos, 81.6ms\n","Speed: 3.5ms preprocess, 81.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","352\n","\n","0: 512x640 2 thit-bos, 1 pho, 66.4ms\n","Speed: 3.3ms preprocess, 66.4ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","353\n","\n","0: 512x640 5 thit-bos, 1 pho, 68.2ms\n","Speed: 3.2ms preprocess, 68.2ms inference, 1.4ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","354\n","\n","0: 576x640 4 thit-bos, 1 pho, 89.9ms\n","Speed: 2.8ms preprocess, 89.9ms inference, 1.2ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","355\n","\n","0: 544x640 4 thit-bos, 2 phos, 92.3ms\n","Speed: 3.7ms preprocess, 92.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","356\n","\n","0: 544x640 5 thit-bos, 3 phos, 88.8ms\n","Speed: 3.8ms preprocess, 88.8ms inference, 1.6ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","357\n","\n","0: 448x640 8 thit-bos, 3 phos, 72.0ms\n","Speed: 1.6ms preprocess, 72.0ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","358\n","\n","0: 640x640 7 thit-bos, 1 pho, 100.4ms\n","Speed: 4.0ms preprocess, 100.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","359\n","\n","0: 544x640 4 thit-bos, 2 phos, 89.7ms\n","Speed: 4.4ms preprocess, 89.7ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","360\n","\n","0: 416x640 3 thit-bos, 2 phos, 70.7ms\n","Speed: 3.8ms preprocess, 70.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","361\n","\n","0: 480x640 5 thit-bos, 3 phos, 74.1ms\n","Speed: 2.6ms preprocess, 74.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","362\n","\n","0: 544x640 7 thit-bos, 3 phos, 89.8ms\n","Speed: 3.5ms preprocess, 89.8ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","363\n","\n","0: 448x640 9 thit-bos, 1 pho, 68.7ms\n","Speed: 3.4ms preprocess, 68.7ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","364\n","\n","0: 480x640 7 thit-bos, 3 phos, 71.1ms\n","Speed: 3.9ms preprocess, 71.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","365\n","\n","0: 480x640 10 thit-bos, 4 phos, 70.1ms\n","Speed: 3.0ms preprocess, 70.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","366\n","\n","0: 416x640 15 thit-bos, 3 phos, 67.8ms\n","Speed: 1.5ms preprocess, 67.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","------\n","367\n","\n","0: 480x640 3 thit-bos, 5 phos, 71.2ms\n","Speed: 2.8ms preprocess, 71.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","------\n","368\n","\n","0: 576x640 8 thit-bos, 3 phos, 91.4ms\n","Speed: 3.0ms preprocess, 91.4ms inference, 2.6ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","369\n","\n","0: 640x640 8 thit-bos, 2 phos, 90.7ms\n","Speed: 3.4ms preprocess, 90.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 640)\n","------\n","370\n","\n","0: 512x640 7 thit-bos, 2 phos, 63.1ms\n","Speed: 3.0ms preprocess, 63.1ms inference, 1.3ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","371\n","\n","0: 448x640 6 thit-bos, 2 phos, 60.4ms\n","Speed: 3.6ms preprocess, 60.4ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","372\n","\n","0: 576x640 5 thit-bos, 2 phos, 76.5ms\n","Speed: 4.9ms preprocess, 76.5ms inference, 1.3ms postprocess per image at shape (1, 3, 576, 640)\n","------\n","373\n","\n","0: 544x640 2 thit-bos, 3 vien-mocs, 77.7ms\n","Speed: 3.7ms preprocess, 77.7ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n","------\n","374\n","\n","0: 608x640 4 thit-bos, 2 phos, 90.3ms\n","Speed: 4.2ms preprocess, 90.3ms inference, 1.3ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","375\n","\n","0: 512x640 3 thit-bos, 4 phos, 64.1ms\n","Speed: 3.8ms preprocess, 64.1ms inference, 1.2ms postprocess per image at shape (1, 3, 512, 640)\n","------\n","376\n","\n","0: 448x640 7 phos, 4 thit-gas, 61.9ms\n","Speed: 2.6ms preprocess, 61.9ms inference, 1.7ms postprocess per image at shape (1, 3, 448, 640)\n","------\n","377\n","\n","0: 640x480 5 thit-bos, 1 pho, 64.0ms\n","Speed: 2.9ms preprocess, 64.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n","------\n","378\n","\n","0: 608x640 10 thit-bos, 2 phos, 81.2ms\n","Speed: 4.1ms preprocess, 81.2ms inference, 1.9ms postprocess per image at shape (1, 3, 608, 640)\n","------\n","379\n","\n","0: 576x640 5 thit-bos, 3 phos, 77.8ms\n","Speed: 3.4ms preprocess, 77.8ms inference, 1.6ms postprocess per image at shape (1, 3, 576, 640)\n","------\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predY)\n","precision = precision_score(true_classes, predY, average='weighted')\n","recall = recall_score(true_classes, predY, average='weighted')\n","f1 = f1_score(true_classes, predY, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predY, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predY)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Go0ZdPD7Gpij","executionInfo":{"status":"ok","timestamp":1718542463618,"user_tz":-420,"elapsed":429,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}},"outputId":"305c35f3-0e8f-438e-cdad-64659ca1eb1a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 94.21052631578948\n","Precision: 95.36190779367773\n","Recall: 94.21052631578948\n","F1 Score: 94.34501455419044\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       0.94      1.00      0.97        15\n","        bun-bo-hue       0.97      0.97      0.97        36\n","            bun-ca       0.65      1.00      0.78        20\n","   bun-dau-mam-tom       1.00      0.92      0.96        25\n"," bun-hai-san-be-be       1.00      0.93      0.97        30\n","           bun-moc       0.95      1.00      0.97        19\n","           bun-muc       0.92      0.92      0.92        13\n","      bun-nuoc-leo       1.00      0.77      0.87        26\n","           cao-lau       0.97      0.92      0.94        37\n","            com-ga       1.00      1.00      1.00        40\n","com-tam-long-xuyen       1.00      1.00      1.00        36\n","    hu-tieu-my-tho       1.00      0.71      0.83        14\n","          mi-quang       0.86      0.94      0.90        33\n","        pho-ha-noi       0.97      0.97      0.97        36\n","\n","          accuracy                           0.94       380\n","         macro avg       0.95      0.93      0.93       380\n","      weighted avg       0.95      0.94      0.94       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 1.00\n","bun-bo-hue: 0.97\n","bun-ca: 1.00\n","bun-dau-mam-tom: 0.92\n","bun-hai-san-be-be: 0.93\n","bun-moc: 1.00\n","bun-muc: 0.92\n","bun-nuoc-leo: 0.77\n","cao-lau: 0.92\n","com-ga: 1.00\n","com-tam-long-xuyen: 1.00\n","hu-tieu-my-tho: 0.71\n","mi-quang: 0.94\n","pho-ha-noi: 0.97\n"]}]},{"cell_type":"markdown","source":["# Kết quả Yolov9 + D2D"],"metadata":{"id":"80rvY4D-Ipqm"}},{"cell_type":"code","source":["file_paths = test_generator.filepaths\n","\n","predY = []\n","\n","for index, img_predict in enumerate(file_paths):\n","    print(index)\n","    food = recognize_food(model_yolov9, img_predict)\n","    # Chuyển đổi từ tên nhãn sang số tương ứng\n","    predicted_index = next((index for index, label in label_to_index.items() if label == food), None)\n","    predY.append(predicted_index)\n","    print(\"------\")"],"metadata":{"id":"G1BZ9AUbInux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predY)\n","precision = precision_score(true_classes, predY, average='weighted')\n","recall = recall_score(true_classes, predY, average='weighted')\n","f1 = f1_score(true_classes, predY, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predY, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predY)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"omzgP9cpIymS","executionInfo":{"status":"ok","timestamp":1718542991110,"user_tz":-420,"elapsed":378,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}},"outputId":"f3d65925-e863-45fe-a505-0fbc098f7b2e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 94.73684210526315\n","Precision: 95.6808044953582\n","Recall: 94.73684210526315\n","F1 Score: 94.80000812820457\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       0.94      1.00      0.97        15\n","        bun-bo-hue       0.95      1.00      0.97        36\n","            bun-ca       0.69      1.00      0.82        20\n","   bun-dau-mam-tom       1.00      0.96      0.98        25\n"," bun-hai-san-be-be       1.00      0.93      0.97        30\n","           bun-moc       1.00      1.00      1.00        19\n","           bun-muc       0.87      1.00      0.93        13\n","      bun-nuoc-leo       1.00      0.73      0.84        26\n","           cao-lau       0.97      0.92      0.94        37\n","            com-ga       1.00      1.00      1.00        40\n","com-tam-long-xuyen       1.00      1.00      1.00        36\n","    hu-tieu-my-tho       1.00      0.79      0.88        14\n","          mi-quang       0.86      0.94      0.90        33\n","        pho-ha-noi       1.00      0.94      0.97        36\n","\n","          accuracy                           0.95       380\n","         macro avg       0.95      0.94      0.94       380\n","      weighted avg       0.96      0.95      0.95       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 1.00\n","bun-bo-hue: 1.00\n","bun-ca: 1.00\n","bun-dau-mam-tom: 0.96\n","bun-hai-san-be-be: 0.93\n","bun-moc: 1.00\n","bun-muc: 1.00\n","bun-nuoc-leo: 0.73\n","cao-lau: 0.92\n","com-ga: 1.00\n","com-tam-long-xuyen: 1.00\n","hu-tieu-my-tho: 0.79\n","mi-quang: 0.94\n","pho-ha-noi: 0.94\n"]}]},{"cell_type":"markdown","source":["# Kết quả RT-DETR + D2D"],"metadata":{"id":"8R673mH6K7V2"}},{"cell_type":"code","source":["file_paths = test_generator.filepaths\n","\n","predY = []\n","\n","for index, img_predict in enumerate(file_paths):\n","    food = recognize_food(model_rtdetr, img_predict)\n","    # Chuyển đổi từ tên nhãn sang số tương ứng\n","    predicted_index = next((index for index, label in label_to_index.items() if label == food), None)\n","    predY.append(predicted_index)"],"metadata":{"id":"53HNZVePK1hR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predY)\n","precision = precision_score(true_classes, predY, average='weighted')\n","recall = recall_score(true_classes, predY, average='weighted')\n","f1 = f1_score(true_classes, predY, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predY, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predY)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FVd71LHqLTF8","executionInfo":{"status":"ok","timestamp":1718543549330,"user_tz":-420,"elapsed":393,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}},"outputId":"9ac45620-ebde-4842-b349-fe5cf20b9598"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 94.73684210526315\n","Precision: 95.93324181566966\n","Recall: 94.73684210526315\n","F1 Score: 94.97862532756365\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       1.00      1.00      1.00        15\n","        bun-bo-hue       1.00      0.94      0.97        36\n","            bun-ca       0.65      1.00      0.78        20\n","   bun-dau-mam-tom       1.00      0.92      0.96        25\n"," bun-hai-san-be-be       1.00      0.93      0.97        30\n","           bun-moc       0.95      1.00      0.97        19\n","           bun-muc       1.00      0.92      0.96        13\n","      bun-nuoc-leo       1.00      0.81      0.89        26\n","           cao-lau       0.94      0.92      0.93        37\n","            com-ga       1.00      1.00      1.00        40\n","com-tam-long-xuyen       1.00      0.97      0.99        36\n","    hu-tieu-my-tho       1.00      0.86      0.92        14\n","          mi-quang       0.84      0.94      0.89        33\n","        pho-ha-noi       1.00      1.00      1.00        36\n","\n","          accuracy                           0.95       380\n","         macro avg       0.96      0.94      0.95       380\n","      weighted avg       0.96      0.95      0.95       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 1.00\n","bun-bo-hue: 0.94\n","bun-ca: 1.00\n","bun-dau-mam-tom: 0.92\n","bun-hai-san-be-be: 0.93\n","bun-moc: 1.00\n","bun-muc: 0.92\n","bun-nuoc-leo: 0.81\n","cao-lau: 0.92\n","com-ga: 1.00\n","com-tam-long-xuyen: 0.97\n","hu-tieu-my-tho: 0.86\n","mi-quang: 0.94\n","pho-ha-noi: 1.00\n"]}]},{"cell_type":"markdown","source":["# Kết quả MobileNet"],"metadata":{"id":"N8dH_55lbFpn"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/object_detection/models/mobilenet.h5')\n","\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average='weighted')\n","recall = recall_score(true_classes, predicted_classes, average='weighted')\n","f1 = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predicted_classes, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5r8pAkBaIhQ","outputId":"de7d9c23-161d-4a27-d43c-c6a4da6e1ad3","executionInfo":{"status":"ok","timestamp":1718543949427,"user_tz":-420,"elapsed":8846,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 6s 288ms/step\n","Accuracy: 63.68421052631579\n","Precision: 73.88131883984464\n","Recall: 63.68421052631579\n","F1 Score: 60.08327421431432\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       1.00      0.73      0.85        15\n","        bun-bo-hue       1.00      0.03      0.05        36\n","            bun-ca       0.43      0.50      0.47        20\n","   bun-dau-mam-tom       0.68      1.00      0.81        25\n"," bun-hai-san-be-be       0.92      0.37      0.52        30\n","           bun-moc       0.93      0.68      0.79        19\n","           bun-muc       0.80      0.31      0.44        13\n","      bun-nuoc-leo       0.93      0.50      0.65        26\n","           cao-lau       0.48      0.92      0.63        37\n","            com-ga       0.75      0.82      0.79        40\n","com-tam-long-xuyen       0.90      0.72      0.80        36\n","    hu-tieu-my-tho       0.67      0.14      0.24        14\n","          mi-quang       0.53      0.85      0.65        33\n","        pho-ha-noi       0.49      0.86      0.63        36\n","\n","          accuracy                           0.64       380\n","         macro avg       0.75      0.60      0.59       380\n","      weighted avg       0.74      0.64      0.60       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 0.73\n","bun-bo-hue: 0.03\n","bun-ca: 0.50\n","bun-dau-mam-tom: 1.00\n","bun-hai-san-be-be: 0.37\n","bun-moc: 0.68\n","bun-muc: 0.31\n","bun-nuoc-leo: 0.50\n","cao-lau: 0.92\n","com-ga: 0.82\n","com-tam-long-xuyen: 0.72\n","hu-tieu-my-tho: 0.14\n","mi-quang: 0.85\n","pho-ha-noi: 0.86\n"]}]},{"cell_type":"markdown","source":["# Kết quả InceptionV3"],"metadata":{"id":"76ySQ8YDb8AX"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/object_detection/models/inceptionv3.h5')\n","\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average='weighted')\n","recall = recall_score(true_classes, predicted_classes, average='weighted')\n","f1 = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predicted_classes, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtR6igxHb3AT","outputId":"ecb243f9-c08a-420b-ca1d-d469da143ee4","executionInfo":{"status":"ok","timestamp":1718544022685,"user_tz":-420,"elapsed":28089,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 15s 805ms/step\n","Accuracy: 52.10526315789473\n","Precision: 60.0072244207116\n","Recall: 52.10526315789473\n","F1 Score: 51.16937473867017\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       0.50      0.73      0.59        15\n","        bun-bo-hue       0.85      0.31      0.45        36\n","            bun-ca       0.28      0.40      0.33        20\n","   bun-dau-mam-tom       0.87      0.52      0.65        25\n"," bun-hai-san-be-be       0.67      0.53      0.59        30\n","           bun-moc       0.41      0.89      0.57        19\n","           bun-muc       0.24      0.54      0.33        13\n","      bun-nuoc-leo       0.85      0.42      0.56        26\n","           cao-lau       0.70      0.43      0.53        37\n","            com-ga       0.46      0.82      0.59        40\n","com-tam-long-xuyen       0.76      0.72      0.74        36\n","    hu-tieu-my-tho       0.00      0.00      0.00        14\n","          mi-quang       0.73      0.24      0.36        33\n","        pho-ha-noi       0.40      0.58      0.47        36\n","\n","          accuracy                           0.52       380\n","         macro avg       0.55      0.51      0.48       380\n","      weighted avg       0.60      0.52      0.51       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 0.73\n","bun-bo-hue: 0.31\n","bun-ca: 0.40\n","bun-dau-mam-tom: 0.52\n","bun-hai-san-be-be: 0.53\n","bun-moc: 0.89\n","bun-muc: 0.54\n","bun-nuoc-leo: 0.42\n","cao-lau: 0.43\n","com-ga: 0.82\n","com-tam-long-xuyen: 0.72\n","hu-tieu-my-tho: 0.00\n","mi-quang: 0.24\n","pho-ha-noi: 0.58\n"]}]},{"cell_type":"markdown","source":["# Kết quả DenseNet201"],"metadata":{"id":"ZTLuWVAQclMl"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/object_detection/models/densenet201.h5')\n","\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average='weighted')\n","recall = recall_score(true_classes, predicted_classes, average='weighted')\n","f1 = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predicted_classes, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t32d7C-gcepu","outputId":"8ef6b561-32b0-4441-8010-59833e843cb0","executionInfo":{"status":"ok","timestamp":1718544066744,"user_tz":-420,"elapsed":39519,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 22s 917ms/step\n","Accuracy: 52.63157894736842\n","Precision: 73.21399868212214\n","Recall: 52.63157894736842\n","F1 Score: 47.302560017313446\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       1.00      0.67      0.80        15\n","        bun-bo-hue       1.00      0.08      0.15        36\n","            bun-ca       1.00      0.10      0.18        20\n","   bun-dau-mam-tom       0.86      1.00      0.93        25\n"," bun-hai-san-be-be       1.00      0.10      0.18        30\n","           bun-moc       0.25      0.84      0.38        19\n","           bun-muc       0.45      0.77      0.57        13\n","      bun-nuoc-leo       1.00      0.15      0.27        26\n","           cao-lau       0.64      0.86      0.74        37\n","            com-ga       0.71      0.68      0.69        40\n","com-tam-long-xuyen       0.61      0.75      0.67        36\n","    hu-tieu-my-tho       0.00      0.00      0.00        14\n","          mi-quang       1.00      0.21      0.35        33\n","        pho-ha-noi       0.33      0.94      0.49        36\n","\n","          accuracy                           0.53       380\n","         macro avg       0.70      0.51      0.46       380\n","      weighted avg       0.73      0.53      0.47       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 0.67\n","bun-bo-hue: 0.08\n","bun-ca: 0.10\n","bun-dau-mam-tom: 1.00\n","bun-hai-san-be-be: 0.10\n","bun-moc: 0.84\n","bun-muc: 0.77\n","bun-nuoc-leo: 0.15\n","cao-lau: 0.86\n","com-ga: 0.68\n","com-tam-long-xuyen: 0.75\n","hu-tieu-my-tho: 0.00\n","mi-quang: 0.21\n","pho-ha-noi: 0.94\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["# Kết quả VGG16"],"metadata":{"id":"ZQlDYBg6X4Xi"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/object_detection/models/vgg16.h5')\n","\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average='weighted')\n","recall = recall_score(true_classes, predicted_classes, average='weighted')\n","f1 = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predicted_classes, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4cpN4WdV9tc","outputId":"c8dcc432-ad7b-4ca9-912f-4debd2e106ba","executionInfo":{"status":"ok","timestamp":1718544126750,"user_tz":-420,"elapsed":28526,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 24s 1s/step\n","Accuracy: 41.05263157894737\n","Precision: 43.79420941351629\n","Recall: 41.05263157894737\n","F1 Score: 35.35201597772743\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       0.56      0.60      0.58        15\n","        bun-bo-hue       0.28      0.58      0.38        36\n","            bun-ca       0.50      0.15      0.23        20\n","   bun-dau-mam-tom       0.50      0.92      0.65        25\n"," bun-hai-san-be-be       0.00      0.00      0.00        30\n","           bun-moc       0.80      0.21      0.33        19\n","           bun-muc       0.00      0.00      0.00        13\n","      bun-nuoc-leo       0.00      0.00      0.00        26\n","           cao-lau       0.50      0.38      0.43        37\n","            com-ga       0.74      0.50      0.60        40\n","com-tam-long-xuyen       0.56      0.69      0.62        36\n","    hu-tieu-my-tho       0.00      0.00      0.00        14\n","          mi-quang       1.00      0.15      0.26        33\n","        pho-ha-noi       0.25      0.89      0.39        36\n","\n","          accuracy                           0.41       380\n","         macro avg       0.41      0.36      0.32       380\n","      weighted avg       0.44      0.41      0.35       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 0.60\n","bun-bo-hue: 0.58\n","bun-ca: 0.15\n","bun-dau-mam-tom: 0.92\n","bun-hai-san-be-be: 0.00\n","bun-moc: 0.21\n","bun-muc: 0.00\n","bun-nuoc-leo: 0.00\n","cao-lau: 0.38\n","com-ga: 0.50\n","com-tam-long-xuyen: 0.69\n","hu-tieu-my-tho: 0.00\n","mi-quang: 0.15\n","pho-ha-noi: 0.89\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["# Kết quả Xception"],"metadata":{"id":"xVGR4BZtZ7Y0"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/object_detection/models/xception.h5')\n","\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average='weighted')\n","recall = recall_score(true_classes, predicted_classes, average='weighted')\n","f1 = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predicted_classes, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCmK27wNX25M","outputId":"1b637a72-59f9-4bda-de31-f76f74cec041","executionInfo":{"status":"ok","timestamp":1718544152739,"user_tz":-420,"elapsed":20545,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 12s 505ms/step\n","Accuracy: 52.10526315789473\n","Precision: 67.46538003996166\n","Recall: 52.10526315789473\n","F1 Score: 49.26466827339202\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       0.65      0.87      0.74        15\n","        bun-bo-hue       0.86      0.17      0.28        36\n","            bun-ca       0.60      0.15      0.24        20\n","   bun-dau-mam-tom       1.00      0.80      0.89        25\n"," bun-hai-san-be-be       0.88      0.47      0.61        30\n","           bun-moc       1.00      0.16      0.27        19\n","           bun-muc       0.67      0.31      0.42        13\n","      bun-nuoc-leo       1.00      0.27      0.42        26\n","           cao-lau       0.53      0.70      0.60        37\n","            com-ga       0.35      0.88      0.50        40\n","com-tam-long-xuyen       0.86      0.33      0.48        36\n","    hu-tieu-my-tho       0.00      0.00      0.00        14\n","          mi-quang       0.68      0.64      0.66        33\n","        pho-ha-noi       0.33      0.94      0.49        36\n","\n","          accuracy                           0.52       380\n","         macro avg       0.67      0.48      0.47       380\n","      weighted avg       0.67      0.52      0.49       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 0.87\n","bun-bo-hue: 0.17\n","bun-ca: 0.15\n","bun-dau-mam-tom: 0.80\n","bun-hai-san-be-be: 0.47\n","bun-moc: 0.16\n","bun-muc: 0.31\n","bun-nuoc-leo: 0.27\n","cao-lau: 0.70\n","com-ga: 0.88\n","com-tam-long-xuyen: 0.33\n","hu-tieu-my-tho: 0.00\n","mi-quang: 0.64\n","pho-ha-noi: 0.94\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["# Kết quả DenseNet121"],"metadata":{"id":"u3RQJJW6gG0d"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","model = tf.keras.models.load_model('/content/drive/MyDrive/object_detection/models/densenet121.h5')\n","\n","predictions = model.predict(test_generator)\n","predicted_classes = np.argmax(predictions, axis=1)\n","\n","# Lấy nhãn thực tế từ generator\n","true_classes = test_generator.classes\n","\n","# Tính các chỉ số đánh giá\n","accuracy = accuracy_score(true_classes, predicted_classes)\n","precision = precision_score(true_classes, predicted_classes, average='weighted')\n","recall = recall_score(true_classes, predicted_classes, average='weighted')\n","f1 = f1_score(true_classes, predicted_classes, average='weighted')\n","\n","# In ra kết quả\n","print('Accuracy:', accuracy * 100)\n","print('Precision:', precision * 100)\n","print('Recall:', recall * 100)\n","print('F1 Score:', f1* 100)\n","\n","# In báo cáo chi tiết\n","print('\\nClassification Report:')\n","print(classification_report(true_classes, predicted_classes, target_names=class_names))\n","\n","# Tính accuracy cho từng nhãn\n","conf_matrix = confusion_matrix(true_classes, predicted_classes)\n","class_accuracies = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n","\n","print('\\nAccuracy for each class:')\n","for class_name, class_accuracy in zip(class_names, class_accuracies):\n","    print(f'{class_name}: {class_accuracy:.2f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mV_YZ8o_f_cS","outputId":"9bc08af8-a85c-4818-e3e0-25e4bdc10c4f","executionInfo":{"status":"ok","timestamp":1718544189121,"user_tz":-420,"elapsed":20280,"user":{"displayName":"Thơ Nguyễn","userId":"07265010138308271454"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["12/12 [==============================] - 7s 364ms/step\n","Accuracy: 51.31578947368421\n","Precision: 67.06676150339067\n","Recall: 51.31578947368421\n","F1 Score: 46.65441021746036\n","\n","Classification Report:\n","                    precision    recall  f1-score   support\n","\n"," banh-hoi-heo-quay       0.82      0.60      0.69        15\n","        bun-bo-hue       1.00      0.03      0.05        36\n","            bun-ca       0.50      0.25      0.33        20\n","   bun-dau-mam-tom       0.81      1.00      0.89        25\n"," bun-hai-san-be-be       0.86      0.40      0.55        30\n","           bun-moc       0.29      0.89      0.44        19\n","           bun-muc       0.36      0.38      0.37        13\n","      bun-nuoc-leo       1.00      0.04      0.07        26\n","           cao-lau       0.67      0.54      0.60        37\n","            com-ga       0.88      0.35      0.50        40\n","com-tam-long-xuyen       0.43      0.89      0.58        36\n","    hu-tieu-my-tho       0.00      0.00      0.00        14\n","          mi-quang       0.80      0.61      0.69        33\n","        pho-ha-noi       0.37      0.94      0.53        36\n","\n","          accuracy                           0.51       380\n","         macro avg       0.63      0.49      0.45       380\n","      weighted avg       0.67      0.51      0.47       380\n","\n","\n","Accuracy for each class:\n","banh-hoi-heo-quay: 0.60\n","bun-bo-hue: 0.03\n","bun-ca: 0.25\n","bun-dau-mam-tom: 1.00\n","bun-hai-san-be-be: 0.40\n","bun-moc: 0.89\n","bun-muc: 0.38\n","bun-nuoc-leo: 0.04\n","cao-lau: 0.54\n","com-ga: 0.35\n","com-tam-long-xuyen: 0.89\n","hu-tieu-my-tho: 0.00\n","mi-quang: 0.61\n","pho-ha-noi: 0.94\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}